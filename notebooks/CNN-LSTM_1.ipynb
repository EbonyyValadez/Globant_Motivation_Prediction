{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5400199c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eeb57cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the dataset.\n",
    "filepath = \"datasets/data_globant_clean.csv\"\n",
    "\n",
    "# We will save the trained CNN model into a file. Specify the path where the model will be saved.\n",
    "savemodelpath = \"datasets/\" # Make sure the directory already exists in your local computer.\n",
    "\n",
    "# Define the size of the images.\n",
    "\n",
    "# Read the dataset.\n",
    "dataset = pd.read_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526eb67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc414077",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"EmployeeID\"] = dataset[\"Name\"].astype(\"category\").cat.codes\n",
    "\n",
    "bins_personalizados = [0.0, 1.5, 3.5, 5.0]\n",
    "labels_personalizados = [\"Bajo\", \"Medio\", \"Alto\"]\n",
    "dataset[\"Engagement_D\"] = pd.cut(dataset[\"Engagement\"], bins = bins_personalizados, labels = labels_personalizados, include_lowest = True)\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d03aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop(columns = [\"Engagement\", \"Name\", \"Email Leader\"])\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfeb274",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    \"EmployeeID\",\n",
    "    \"Seniority\",\n",
    "    \"Month\",\n",
    "    \"Day\",\n",
    "    \"Position\",\n",
    "    \"Location\",\n",
    "    \"Studio\",\n",
    "    \"Client Tag\",\n",
    "    \"Project Tag\",\n",
    "    \"Team Name\",\n",
    "]\n",
    "\n",
    "target = \"Engagement_D\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9714309d",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = [\n",
    "    \"Position\",\n",
    "    \"Location\",\n",
    "    \"Studio\",\n",
    "    \"Client Tag\",\n",
    "    \"Project Tag\",\n",
    "    \"Team Name\",\n",
    "]\n",
    "\n",
    "encoders = {}\n",
    "\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    dataset[col] = le.fit_transform(dataset[col])\n",
    "    encoders[col] = le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1946d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_target = LabelEncoder()\n",
    "dataset[\"Engagement_D\"] = encoder_target.fit_transform(dataset[\"Engagement_D\"].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289d92c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"Date\"] = pd.to_datetime(dataset[\"Date\"], format=\"%d%b%y\")\n",
    "dataset = dataset.sort_values([\"EmployeeID\", \"Date\"])\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bacf8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "num_cols = [\"Seniority\", \"Month\", \"Day\"]\n",
    "\n",
    "dataset[num_cols] = scaler.fit_transform(dataset[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272cb847",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset[features].dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7b6b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_windows(df, features, target, window=14):\n",
    "    X, y = [], []\n",
    "\n",
    "    for emp in df[\"EmployeeID\"].unique():\n",
    "        emp_data = df[df[\"EmployeeID\"] == emp]\n",
    "\n",
    "        if len(emp_data) <= window:\n",
    "            continue  # empleado con pocos datos\n",
    "\n",
    "        f_vals = emp_data[features].values\n",
    "        t_vals = emp_data[target].values\n",
    "\n",
    "        for i in range(len(emp_data) - window):\n",
    "            X.append(f_vals[i:i+window])\n",
    "            y.append(t_vals[i+window])\n",
    "\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X, y = create_windows(dataset, features, target, window=14)\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c38f49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(X)\n",
    "\n",
    "test_size = 0.10\n",
    "val_size = 0.10\n",
    "\n",
    "train_end = int(n * (1 - test_size - val_size))  # 80%\n",
    "val_end   = int(n * (1 - test_size))             # 90%\n",
    "\n",
    "# Features\n",
    "X_train = X[:train_end]\n",
    "X_val   = X[train_end:val_end]\n",
    "X_test  = X[val_end:]\n",
    "\n",
    "# Labels\n",
    "y_train = y[:train_end]\n",
    "y_val   = y[train_end:val_end]\n",
    "y_test  = y[val_end:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842ee202",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_train)\n",
    "plt.xlabel(\"Tiempo\")\n",
    "plt.ylabel(\"Engagement\")\n",
    "plt.title(\"Conjunto de train\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(y_test)\n",
    "plt.xlabel(\"Tiempo\")\n",
    "plt.ylabel(\"Engagement\")\n",
    "plt.title(\"Conjunto de test\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe06808",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsequences = 2\n",
    "timesteps = X_train.shape[1] // subsequences\n",
    "features_n = X_train.shape[2]\n",
    "\n",
    "X_train = X_train.reshape((X_train.shape[0], subsequences, timesteps, features_n))\n",
    "X_test  = X_test.reshape((X_test.shape[0], subsequences, timesteps, features_n))\n",
    "X_val = X_val.reshape((X_test.shape[0], subsequences, timesteps, features_n))\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ee2fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import TimeDistributed, Conv1D, MaxPooling1D, Flatten, LSTM, Dense\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(TimeDistributed(\n",
    "    Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
    "    input_shape=(subsequences, timesteps, features_n)\n",
    "))\n",
    "\n",
    "model.add(TimeDistributed(\n",
    "    Conv1D(filters=64, kernel_size=2, activation='relu')\n",
    "))\n",
    "\n",
    "model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model.add(LSTM(50, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))  \n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.005),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df9ac87",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252287e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804c76cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(\"Test accuracy:\", test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mv-tec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
